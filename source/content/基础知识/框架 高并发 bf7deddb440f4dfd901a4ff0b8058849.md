# 框架/高并发

Owner: yancy yu

### 什么是QPS

QPS（Queries Per Second，每秒查询数）是衡量系统吞吐量的一个常用指标，用于描述系统每秒能够处理的查询或请求的数量。然而，理论最大并发数（在这里是24,576）和QPS不是直接相等的，因为它们衡量的是不同方面的系统性能。

### 如何计算QPS

QPS取决于以下几个因素：

1. **请求处理时间**：每个请求从开始到结束所需的时间。
2. **并发数量**：系统同时处理的请求的数量。

QPS大致可以用以下公式来计算：
QPS = {并发数量} /{平均请求处理时间}

### 需要注意的因素

1. **请求的复杂性**：如果每个请求都非常复杂，需要大量的CPU或I/O操作，那么即使并发数很高，QPS也可能会降低。
2. **网络延迟和带宽**：网络带宽和延迟也会影响QPS。如果网络带宽不足或者延迟太高，高并发也无法转化为高QPS。
3. **其他资源限制**：包括数据库速度、磁盘I/O等也可能成为瓶颈。
4. **系统优化**：包括负载均衡、缓存等优化措施也会影响实际QPS。

因此，理论上的24,576并发不代表你可以达到24,576 QPS。实际的QPS需要通过压力测试来确定。

一般来说，一个健康、优化良好的web应用，每个请求的处理时间可能在几十毫秒到几百毫秒之间。因此，如果假设平均每个请求处理时间为100毫秒（0.1秒），那么理论上的QPS上限为：
**QPS = 24576 / 0.1 = 245,760**

但这仅仅是理论上的最大值，实际QPS可能会由于上述多种因素而有所不同。最佳实践是进行实际的负载和性能测试来确定可支持的QPS。

### Flask底层原理

- Flask基于WSGI (Web Server Gateway Interface)来进行HTTP请求和响应的处理。
- Werkzeug库用于处理请求、路由和HTTP相关的一系列功能。
- 使用Jinja2作为模板引擎。
    
    ### 高并发
    
    - 默认的开发服务器不适用于生产环境。
    - 通常与Gunicorn或uWSGI等WSGI服务器配合，后面可以接Nginx作为反向代理。
    - 可以通过多进程或多线程来处理并发。

### flask的WSGI服务器（Gunicorn）配置

<aside>
❓ 配置文件
# -*- coding: utf-8 -*-

# 多进程
import multiprocessing
"""gunicorn+gevent 的配置文件"""

# 预加载资源
# preload_app = True
# 绑定 ip + 端口
bind = "0.0.0.0:5000"
# 进程数 = cpu数量
workers = multiprocessing.cpu_count()

# 线程数 = cpu数量
threads = 1

# 等待队列最大长度,超过这个长度的链接将被拒绝连接
backlog = 2048

# 工作模式--协程
worker_class = "gevent"

# 最大客户客户端并发数量,对使用线程和协程的worker的工作有影响
# 服务器配置设置的值  1200：中小型项目  上万并发： 中大型
# 服务器硬件：宽带+数据库+内存
# 服务器的架构：集群 主从
worker_connections = 2048

from dotenv import load_dotenv

load_dotenv(verbose=True)
from common_sdk.logging.logger import logger
from gunicorn import glogging

class GLogger(glogging.Logger):

    def setup(self, cfg):
        super().setup(cfg)
        self._set_handler(self.error_log, cfg.errorlog, logger.formatter)

logger_class = GLogger

</aside>

<aside>
✅ 这是一个典型的 Gunicorn 配置文件，用于部署 Python Web 应用。配置文件中的各个参数都有特定的目的和作用，具体如下：

### `bind = "0.0.0.0:5000"`

这一行指定 Gunicorn 将监听所有可用的网络接口（0.0.0.0）在端口 5000。这样，任何能够访问这个服务器的客户端都能够连接到这个应用。

### `workers = multiprocessing.cpu_count()`

这里设置工作进程的数量等于 CPU 的核心数。一般来说，这样设置可以充分利用服务器的 CPU 资源。

### `threads = 1`

每个工作进程只有一个线程。因为你用了 Gevent 作为 worker，这样设置是合理的。Gevent 是一个基于协程的库，能够在单线程内异步处理多个连接。

### `backlog = 2048`

这个参数设置了等待队列的最大长度。这是 OS 层面的 TCP 连接等待队列，超过这个数的新连接请求将会被拒绝。一般来说，除非你预计会有非常高的并发连接，否则默认值（通常是 2048 或者更低）就足够了。

### `worker_class = "gevent"`

这里指定使用 Gevent 作为工作模式。Gevent 是一个基于协程的 Python 网络库，它允许高效地处理 I/O-bound 操作。

### `worker_connections = 2048`

这个参数限制了每个 worker（在这种情况下是 Gevent worker）可以同时打开的最大客户端连接数。2048 是一个相当高的数字，适用于高并发环境。

### `from dotenv import load_dotenv` 和 `load_dotenv(verbose=True)`

这两行用于加载环境变量。`dotenv` 库从 `.env` 文件中读取环境变量，并将它们添加到环境中。这对于保密和配置管理是很有用的。

### 自定义日志类 `GLogger`

这部分代码定义了一个自定义的 Gunicorn 日志处理类，它继承自 Gunicorn 的默认日志处理类，并且用自定义的日志格式器进行了扩展。

### `logger_class = GLogger`

这里指定使用自定义的日志类作为 Gunicorn 的日志处理器。

### 关于 Worker

Worker 是 Gunicorn 创建的子进程，用于处理客户端的请求。每个 Worker 都是应用程序代码的一个独立实例。Worker 的数量和类型（同步，异步，基于线程等）可以通过配置文件或命令行参数进行设置。

在这个配置文件中，你选择了 Gevent 作为 Worker 类型（`worker_class = "gevent"`），这意味着每个 Worker 都将使用 Gevent 进行异步 I/O 操作。

总体而言，这个配置文件针对中到大型的 Web 应用进行了优化，特别是那些需要处理大量并发 I/O-bound 请求的应用。

</aside>

根据你提供的 Gunicorn 配置文件，以下几个参数是影响并发能力的关键：

- `workers = multiprocessing.cpu_count()`: 根据 CPU 核数来设置 worker 数量。每个 worker 是一个进程，能够独立地处理请求。
- `worker_class = "gevent"`: 使用 Gevent 作为 worker 类型，这是一个基于协程的库，能够在单个线程里面异步处理多个 I/O-bound 请求。
- `worker_connections = 2048`: 这个参数设置了每个 Gevent worker 可以同时处理的最大连接数。

### 计算并发能力

并发能力大致可以估算为 `workers数量 × worker_connections数量`。假设你有一个 4 核 CPU，那么 workers 数量将是 4（根据 `multiprocessing.cpu_count()`）。每个 worker 可以处理 2048 个连接（根据 `worker_connections`）。

所以，理论上最大的并发能力将是 4 × 2048 = 8192。

### 注意事项

1. **实际并发能力可能低于理论值**: 系统资源、网络延迟、数据库查询速度等多种因素都会影响实际并发能力。
2. **CPU-bound 任务**: 如果你的应用有 CPU-bound 的操作（如复杂的数据处理），Gevent worker 可能不是最佳选择。在这种情况下，异步 IO 的优势将被抵消。
3. **资源限制**: 操作系统和硬件（如内存、网络带宽）也会对并发性能有所限制。
4. **其他系统组件**: 如果你的应用依赖于数据库、缓存或其他外部服务，那么这些服务的性能也会影响到你的并发能力。
5. **代码优化**: 应用代码的效率也是一个重要因素。例如，慢查询和内存泄漏等问题会显著降低并发性能。

<aside>
❓ 我的机器有 16GB 的内存

</aside>

<aside>
✅ 在讨论并发能力时，我们需要考虑多个因素，包括 CPU 核数、网络带宽、内存以及硬盘 I/O。具体到你的问题，你的机器有 16GB 的内存。

### 计算方法

根据你的 Gunicorn 配置文件，理论上的并发数是：
并发能力 = {workers数量} \times * worker_connections数量

### 内存限制

每个 Gevent worker 在处理 I/O-bound 任务时通常消耗的内存相对较少，可能在几十 MB 到几百 MB 之间。因此，16GB 的内存通常不会成为瓶颈。

### 网络带宽

网络带宽可能是限制并发能力的关键因素。

1. **低带宽（比如 10Mbps）**: 在这种情况下，网络可能会成为瓶颈。即使你的服务器能够处理更多的并发连接，网络带宽也可能限制你的吞吐量。
2. **中等带宽（比如 100Mbps）**: 在这种情况下，你的服务器可能能够充分利用配置文件中设置的并发连接数（比如 8192），但这也取决于每个请求和响应的大小。
3. **高带宽（比如 1Gbps 或更高）**: 在这种情况下，网络瓶颈的可能性相对较低，服务器的并发能力更可能受到 CPU 或其他资源的限制。

### 总结

- 对于低带宽，实际可实现的并发数可能会受到严重限制。
- 对于中等带宽，可能接近或达到你在配置文件中设置的最大并发数。
- 对于高带宽，网络不太可能成为限制因素，你可能需要关注其他瓶颈，如 CPU 资源。

请注意，这些都是基于一般经验和理论的估算，实际情况可能因应用的具体需求和行为而有所不同。最好的方式是进行实际的性能测试，以确定在特定条件下的实际并发能力。

</aside>

<aside>
❓ 低带宽（10 Mbps = 1.25 MBps）网络对并发的影响

</aside>

<aside>
✅ 低带宽会限制并发能力主要出于以下几个原因：

### 数据传输瓶颈

1. **有限的吞吐量**: 在低带宽的网络环境下，网络接口的数据传输能力有限。这意味着，即使服务器能够快速处理请求，数据包的传输速度依然会受到带宽的限制。
2. **高延迟**: 低带宽通常意味着网络传输的延迟较高，这将进一步增加处理每个请求所需的总时间，从而降低并发能力。

### 资源竞争和拥塞

1. **TCP 握手和慢启动**: 在带宽较低的情况下，TCP 协议的特性（如三次握手和拥塞控制）可能会导致网络资源的进一步竞争和拥塞，进而降低并发处理能力。
2. **包丢失和重传**: 在带宽有限的网络中，数据包的丢失概率通常会增加，这将触发 TCP 的重传机制，进一步消耗带宽和增加延迟。

### 应用层限制

1. **低吞吐量**: 对于数据传输密集型的应用，如文件上传/下载或流媒体服务，低带宽将直接限制应用的并发吞吐量。
2. **限制用户体验**: 由于低带宽导致的高延迟和低吞吐量，最终用户可能会面临更慢的加载时间和响应时间，从而影响整体的服务质量。

简而言之，即使从计算和内存角度看，服务器具有很高的并发处理能力，低网络带宽仍然可能成为系统性能的瓶颈。在这种情况下，提高带宽通常是提高并发能力和用户体验的有效方法。

</aside>

### FastAPI底层原理

- 使用Pydantic进行数据验证和序列化。
- 内部基于Starlette实现，支持ASGI (Asynchronous Server Gateway Interface)。
- 支持WebSockets和GraphQL。
    
    ### 高并发
    
    - 原生支持异步编程，可以使用Python的`async/await`进行IO-bound操作。
    - 可以与Uvicorn、Hypercorn等ASGI服务器配合使用。
    - 利用Python的异步库，如HTTPx，进行高效的IO操作。

### Django底层原理

- 遵循WSGI标准。
- 使用自己的ORM和模板引擎。
- 采用MTV (Model-Template-View) 架构。
    
    ### 高并发
    
    - 与uWSGI或Gunicorn等WSGI服务器配合。
    - 使用多进程或多线程。
    - 可以使用数据库连接池和缓存来提高性能。

### Beego底层原理

- 使用Go的标准库`net/http`进行HTTP处理。
- 有自己的路由分发机制和MVC（Model-View-Controller）架构。
    
    ### 高并发
    
    - Go本身就是为并发设计的，使用Goroutine来实现轻量级的线程。
    - 无需额外的服务器或反向代理，但也可以与Nginx等配合。
    - 可以利用Go的channel和锁等机制进行高效的并发编程。

### 高并发的通用方法

1. **负载均衡**: 使用Nginx或HAProxy进行负载均衡，分发请求到多个实例。
2. **数据库优化**: 使用连接池、缓存和读写分离。
3. **异步编程**: 对于IO-bound操作，使用异步编程可以显著提高吞吐量。
    
    对于 I/O-bound 操作（如网络请求、文件读写等），主要瓶颈通常不是 CPU，而是等待 I/O 操作的完成。在传统的同步编程模型中，当一个线程进行 I/O 操作时，它会被阻塞，即使 CPU 完全空闲，也无法进行其他任务。这导致了资源的低效利用。
    
    异步编程模型解决了这个问题，其主要优势如下：
    
    1. **高效的资源利用**
    - 在异步模型中，当程序发起一个 I/O 操作并等待其完成时，它不会被阻塞。相反，它会释放 CPU 来执行其他任务。这意味着单个线程可以管理多个 I/O-bound 操作，从而更有效地利用 CPU。
    1. **提高吞吐量和响应性**
    - 由于一个线程能够处理多个操作，因此吞吐量（单位时间内完成的操作数）会显著提高。
    - 此外，由于程序能够快速地从一个任务切换到另一个任务，因此系统的响应时间通常也会更短。
    1. **简化并发管理**
    - 异步编程通常使用事件循环来管理所有的 I/O 操作和其他任务。这消除了使用多线程时常见的问题，如线程同步和死锁。
    1. **降低开销**
    - 线程和进程的创建和销毁都需要相对较大的开销。因为异步编程允许单个线程高效地执行多个任务，所以通常可以降低这种开销。
    
    例如，在 Python 中，`asyncio` 库提供了异步 I/O 支持，使得在 I/O-bound 操作上性能得到明显提升。与此类似，在 Node.js 和 Go 语言中也有原生的异步 I/O 支持。
    
    总体而言，异步编程是 I/O-bound 操作优化的有效手段，它能够显著提高应用程序在高并发环境下的性能。
    
4. **缓存**: 使用Redis或Memcached来缓存热点数据。
5. **队列**: 对于CPU-bound操作，使用消息队列如RabbitMQ或Kafka来进行解耦和异步处理。
    
    对于 CPU-bound 操作，任务通常需要大量的计算资源，因此可能会阻塞或延迟其他类型的任务。在这种场景下，使用消息队列（如 RabbitMQ 或 Kafka）进行解耦和异步处理有多个好处
    
    1. **负载均衡**
    - 消息队列可以作为一个缓冲区，存储突然涌入的大量任务。这样，后端服务可以根据其处理能力，逐一从队列中取出任务进行处理。
    1. **提高系统弹性**
    - 由于生产者和消费者是解耦的，所以即使处理任务的服务（消费者）暂时崩溃或需要进行维护，任务仍然可以被安全地存储在消息队列中，等待恢复后再进行处理。
    1. **可扩展性**
    - 使用消息队列的架构通常更容易水平扩展。当需要更多的计算资源来处理 CPU-bound 任务时，可以简单地增加处理这些任务的服务实例（消费者），而不需要修改已有的代码。
    1. **任务调度和优先级**
    - 消息队列允许更灵活的任务调度。例如，你可以用优先级队列来确保重要的任务首先被执行。
    1. **异步处理**
    - 通过消息队列，生产者无需等待 CPU-bound 任务的完成，就可以继续执行其他任务。这样可以提高系统的响应性。
    
    ### 易于监控和调试
    
    - 使用消息队列使系统更加模块化，更容易进行监控和调试。例如，可以容易地追踪哪些任务已经完成，哪些任务正在等待处理。
    
    对于 CPU-bound 操作，采用消息队列能够提高系统的整体性能和可靠性，同时还提供了更大的灵活性来应对不同的工作负载和优先级。这是为什么在需要处理大量 CPU-bound 任务的复杂系统中，消息队列通常被视为一个很好的解决方案。
    

### WSGI (Web Server Gateway Interface)

- **定义**: WSGI是Python中用于连接Web服务器和Web应用程序的接口标准。
- **作用**: 定义了Web服务器如何与Python应用程序进行交互，以及如何处理请求和响应。
- **实现**: 它是一个在PEP 3333中定义的规范，不是一个软件或工具。
- **示例**: 一个简单的WSGI应用可能是一个Python函数，该函数接受两个参数：一个环境字典和一个开始响应的回调函数。

### uWSGI

- **定义**: uWSGI是一个Web服务器，它实现了WSGI、uwsgi和http协议。
- **作用**: 它是一个应用容器，可以接受客户端或Web服务器的请求，然后将这些请求代理到WSGI应用。
- **实现**: 它是一个具体的软件，通常用C语言编写，性能优越。
- **示例**: uWSGI可以与Nginx或Apache等Web服务器配合使用，通过uwsgi或http协议与它们通信。

### uwsgi (小写)

- **定义**: uwsgi是uWSGI服务器支持的一种二进制协议。
- **作用**: 用于uWSGI与Web服务器（如Nginx）之间的通信。
- **实现**: 这是一个二进制协议，专为性能优化而设计。
- **示例**: 在Nginx中，你可以配置uwsgi_pass来将请求转发到运行uWSGI的应用。

### 区别

1. **WSGI**: 是一个Python的标准接口，用于Web服务器和Python Web应用或框架之间的通信。
2. **uWSGI**: 是一个WSGI的Web服务器/应用服务器。它也是一个项目，提供了实现WSGI和其他多种协议的应用容器。
3. **uwsgi**: 是uWSGI服务器使用的一种协议，用于与其他Web服务器通信。

总结起来，WSGI是一种规范/标准，uWSGI是实现这个规范的一个应用服务器，而uwsgi是uWSGI支持的一个专有协议。希望这能解答你的疑问。如果你有更多问题，随时提出。

[Dapr](Dapr%20afd2b7576b4c4992b1be279577143312.md)

[ZooKeeper组件](ZooKeeper%E7%BB%84%E4%BB%B6%204452c0888cb940a0a55c275884d12e50.md)

[**kafka**](kafka%20a540929c45b243fb8293b23944aadd61.md)