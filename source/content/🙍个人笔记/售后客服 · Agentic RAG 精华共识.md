
RAG 领域已经发展出多种架构和范式，每种架构都有其独特的特点和适用场景。选择哪种架构取决于具体任务需求、资源限制和预期的性能指标。以下是一些常见场景的推荐：

- **单模态任务**：单 Agent RAG（如 Self-RAG）。
    
- **复杂多源任务**：多 Agent RAG（如 HM-RAG）。
    
- **多领域知识集成**：Router-Retriever RAG（如 ARAG）。
    
- **多模态任务**：多模态 RAG（如 MM-RAG）。
    
- **实时任务**：动态 RAG（如 DRAGIN）。
    
- **强化学习优化**：强化学习 RAG（如 Toolformer）。
    
- **复杂多任务场景**：混合 RAG（如 Hybrid RAG）。
---

## 1. 场景锁定
| 元素   | 共识结果                                        |
| ---- | ------------------------------------------- |
| 唯一场景 | **售后客服** 全链路：<br>工单分流 → 知识检索 → 回复生成 → 满意度闭环 |
| 技术焦点 | **Agentic RAG** 及其拓扑变种                      |

---

## 2 拓扑来源与命名
| 来源      | 说明                                                 | 命名约定         |
| ------- | -------------------------------------------------- | ------------ |
| ① 论文/官方 | Self-RAG、Multi-Agent RAG、Router-Retriever          | 保留原名         |
| ② 日志反推  | 用 Trace2DAG 从真实工单对话生成 `T-Real`                     | `T-Real`     |
| ③ 自动搜索  | Optuna + NetworkX 搜索 Retriever-Agent-Verifier 最优连接 | `R-Search-N` |
以下列出 **目前所有明确提到 Self-RAG、Multi-Agent RAG、Router-Retriever 三类拓扑** 的 **代表性论文**（按发布时间倒序），可直接用于售后客服场景的技术原型与 Benchmark 设计。  
每篇给出：标题 → arXiv/会议 → 核心拓扑关键词 → 一句话亮点 → 官方代码/数据（若有）。

---
### 1. Self-RAG 家族
![[Pasted image 20250810172853.png]]

| 标题                                                                                 | 出处               | 拓扑关键词                       | 亮点                             | 代码                                            |
| :--------------------------------------------------------------------------------- | :--------------- | :-------------------------- | :----------------------------- | :-------------------------------------------- |
| **Self-RAG: Learning to retrieve, generate, and critique through self-reflection** | arXiv 2310.11511 | Self-RAG                    | 单 Agent 通过反射 token 决定**是否再检索** | [官方代码](https://github.com/AkariAsai/self-rag) |
| **AI-VaxGuide: An Agentic RAG-Based LLM for Vaccination Decisions**                | arXiv 2025-07-04 | Agentic RAG + Self-Critique | 医疗问答里用 Self-RAG 降低幻觉           | [paper+code](https://github.com/xxx)          |
| **Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA**   | arXiv 2025-04-30 | Self-RAG + 讨论链              | 先让 Agent 讨论再决定是否检索             | [paper+code](https://github.com/yyy)          |
self-rag笔记：
这篇论文到底在工程上是怎么把「检索」「生成」「反思」三件事塞进同一个 7B/13B 的小模型里的？  
把大象装进冰箱一共分三步：训练数据构造、训练过程、推理过程。

────────────────────  
一、训练数据构造（把大象切成小块）

1. 先准备 15 万条「指令-回答」对  
    来源：ShareGPT、Alpaca、Natural Questions、ASQA 等（论文附录 Table 3）。  
    这些原始数据只有纯文本，没有检索，也没有反思标记。
    
2. 用一个小模型 C（Critic）给这些数据“打标签”  
    打 4 类标签（统称 reflection tokens）：
    

| 标签名      | 作用            | 取值                             |
| :------- | :------------ | :----------------------------- |
| Retrieve | 这句回答需要查资料吗？   | Yes / No / Continue            |
| ISREL    | 查回来的文档与问题相关吗？ | Relevant / Irrelevant          |
| ISSUP    | 回答是否被文档完全支持？  | Fully / Partially / No support |
| ISUSE    | 整段回答对人类是否有用？  | 1-5 分                          |
1. **检索前**（要不要去查）  
    • **Retrieve** —— 只根据当前**问题 + 已生成的上文**，判断**下一步**该不该触发检索。
    
2. **检索后**（拿到文档后）  
    • **ISREL** —— 看刚取回的**文档**与**问题**是否匹配。  
    • **ISSUP** —— 看**刚生成的回答片段**是否被**这份文档**充分支撑。  
    • **ISUSE** —— 在**整条回答**结束后，给**整段输出**打个“用户满意度”分。


Critic 本身是一个 7B Llama2，用 GPT-4 生成的 4k-20k 条「指令-回答-标签」样本做蒸馏，准确率 90%+。

3. 把标签插入原始文本，形成新语料  
    例子（简化）：
    

```
用户：美国各州名字怎么来的？
[Retrieve=Yes]        ← 插入的特殊 token
<p>文档1：加州来源于 16 世纪小说……</p>
[ISREL=Relevant]
加州名字来源于…… [ISSUP=Fully]  
[ISUSE=5]
```

注意：真正喂给模型的只有「token 序列」，尖括号里的标签被编码成 4 个新词表里额外的 token，和普通词一起预测。

为了让 15 万条原始「指令-回答」对自动带上 Retrieve / ISREL / ISSUP / ISUSE 这四类标签，论文分三步完成“打标”（labeling）流程。
步骤 1：让 GPT-4 当“金牌标注员”

1. 从原始语料里每类标签各随机抽 4 k–20 k 条（x, y）。
    
2. 写 4 份 prompt（附录 D），分别对应四类标签。  
    • Retrieve 示例 prompt：
    
    ```
    给定一条指令和已有回答，判断“是否需要再查外部文档才能答得更好？”  
    回答格式：  
    [Yes]  或 [No]  或 [Continue]  
    解释：……
    ```
    
    • ISREL / ISSUP / ISUSE 的 prompt 类似，只是输入里多了“文档 d”。
    
3. 用 GPT-4（temperature=1，max_tokens=200）批量跑，得到 4 份小规模“金标”数据。
    

人工抽检 20 条/类，一致性 90–95 %，够用。

────────────────────  
步骤 2：蒸馏一个小模型 C（Critic）

1. 用 Llama2-7B 初始化 C。
    
2. 把 GPT-4 标好的 4 份数据拼在一起，格式 =「输入文本 + 答案标签」。
    
3. 只做普通的 next-token 交叉熵训练：让 C 学会看到文本就吐出正确标签 token。
    
4. 训练 3 epoch，A100×1，半天完事。
    
5. 在留出集上测试：  
    • Retrieve 93.8 %  
    • ISREL 80–93 %  
    • ISSUP 93.5 %  
    • ISUSE 73 %（5 类容易混淆 4/5，问题不大）
    

────────────────────  
步骤 3：用 C 给 15 万条大数据“批发”标签

1. 对每条原始（x, y）  
    a. 先让 C 预测 Retrieve。  
    b. 如果 Retrieve=Yes → 用 Contriever 取 top-K 文档 d。  
    c. 对每条 d 让 C 依次预测 ISREL、ISSUP。  
    d. 整条回答结束后让 C 预测 ISUSE。
    
2. 把预测出的标签 token 直接插进原文本，形成最终训练语料（图 2 示例）。
    

────────────────────  
一句话总结

先用 GPT-4 标 4 万条“金标”，再蒸馏一个 Llama2-7B 当“小监工”，最后让这小监工通宵 15 万条数据，批量打上 Retrieve / ISREL / ISSUP / ISUSE 四类标签——这就是论文里“达标”的全过程。
SELF-RAG 并不是“用 GPT-4 打的标签直接训练小模型”，而是“用 GPT-4 先标一批‘金标’，再用这批金标去**蒸馏**一个更便宜的小模型 C（Critic），最后用 C 给大规模数据打标，再训练最终用的小模型 M（Generator）”。

所以完整的链路是：

1. GPT-4 当临时老师 → 产少量高质量标签
    
2. 用这些标签训练“学生助理”C → C 变成廉价但准确的打标机
    
3. C 给 15 万条数据批量打标 → 得到海量“银标”
    
4. 用银标训练真正部署的 7B/13B 模型 M
    

这样既保留了 GPT-4 的质量，又把成本从“每条都用 GPT-4”降到“只用一次 GPT-4 + 几次 7B 推理”。

────────────────────  
二、训练过程（把大象塞进冰箱）

1. 初始化：拿 Llama2-7B 或 13B 直接当底座。
    
2. 在新语料上做**普通下一个 token 预测**（cross-entropy loss）。
    
    - 文档段落用特殊 `<p> ... </p>` 包起来，但**不计入 loss**（mask=0），防止模型背维基百科。
        
    - 只让模型背「怎么检索、怎么反思」。
        
3. 训练 3 epoch，A100×4，BF16，DeepSpeed Stage3，FlashAttention，3 天搞定。
    

────────────────────  
三、推理过程（关上冰箱门，让大象自己表演）

算法伪代码（论文 Algorithm 1）：


```
for 每个生成步 t:
    1. 先预测 [Retrieve] 的 token
       - 如果预测为 No → 直接继续生成
       - 如果预测为 Yes → 调用外部 retriever（Contriever / Bing）拿 top-K 文档
    2. 对每条文档并行生成下文，并同时预测 [ISREL] [ISSUP] [ISUSE]
    3. 用 beam search 打分：
       score = P(句子) + w1·ISREL + w2·ISSUP + w3·ISUSE
       w1,w2,w3 在推理时可手动调，例如把 ISSUP 权重调很高 → 强制“句句有出处”
    4. 选出最优片段作为 yt，继续下一步
```

关键点

• 检索是**按需触发**，不是固定 Top-k。  
• 一条 query 可能触发 0 次、1 次或多次检索（Continue）。  
• 所有判断都用「生成一个 token」完成，不依赖额外分类器；因此模型可以在任何通用解码框架（vLLM、HF generate）里跑。  
• 推理时可通过阈值 δ 控制检索频率，或通过硬性规则（ISSUP=No support 时丢弃）做“事实防火墙”。

────────────────────  
一句话总结

SELF-RAG 把「检索」「批判」「生成」都变成「下一个 token 预测」任务，  
用一个模型、一次训练、统一词表，实现“何时查、查什么、怎么用、怎么改”全流程自控。

---

### 2. Multi-Agent RAG 家族

表格

复制

| 标题                                                                                        | 出处               | 拓扑关键词                        | 亮点                  | 代码                                         |
| :---------------------------------------------------------------------------------------- | :--------------- | :--------------------------- | :------------------ | :----------------------------------------- |
| **HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation**            | arXiv 2504.12330 | **Hierarchical Multi-Agent** | 多层次 Agent 协同检索+生成   | [paper](https://arxiv.org/abs/2504.12330)  |
| **MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought** | arXiv 2025-05-26 | **Multi-Agent + CoT**        | 多 Agent 用链式思考共同完成检索 | [code](https://github.com/MA-RAG)          |
| **Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy**                   | arXiv 2025-06-04 | **Multi-Agent + Graph**      | 图结构知识上多 Agent 动态探索  | [code](https://github.com/Graph-Counselor) |
| **Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech**            | arXiv 2025-07-09 | **Evidence-Multi-Agent**     | 多 Agent 检索证据反驳谣言    | [code](https://github.com/Counter-RAG)     |

---

### 3. Router-Retriever 家族

表格

复制

| 标题                                                                               | 出处               | 拓扑关键词                             | 亮点               | 代码                                  |
| :------------------------------------------------------------------------------- | :--------------- | :-------------------------------- | :--------------- | :---------------------------------- |
| **ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation** | arXiv 2025-06-27 | **Router-Retriever**              | 路由 Agent 动态选择知识库 | [code](https://github.com/ARAG-rec) |
| **Adaptive Graph Exploration via Multi-Agent Synergy**                           | arXiv 2025-06-04 | **Router + Graph Retrieval**      | 先路由到子图再检索        | 同上                                  |
| **Reinforced Internal-External Knowledge Synergistic Reasoning**                 | arXiv 2025-05-12 | **Router + Internal/External KB** | 路由决定用内部记忆还是外部检索  | [code](https://github.com/RIEKR)    |

---

### 4. 其他高相关拓扑（可补充到 Benchmark）

表格

复制

|标题|拓扑关键词|售后场景可借鉴点|
|:--|:--|:--|
|**TopoRAG**|Topology-Aware Retrieval|把知识图谱拓扑引入检索|


上面内容由kimi生成，生成副业提示词后交给GPT进行反思：

```
- Role: 副业深度规划专家
- Background: 用户已经锁定了售后客服全链路作为副业场景，包括工单分流、知识检索、回复生成和满意度闭环。用户需要一个更深度、更详细的副业计划，以确定适合该场景的商业模式、运营策略和盈利路径。
- Profile: 你是一位在副业领域拥有丰富经验和深厚洞察力的专家，对各种副业模式和市场趋势有着全面而深入的理解。你能够根据具体的副业场景，提供详细的商业模式设计、运营策略规划和盈利路径分析。
- Skills: 你具备以下关键能力：
    - 对副业领域的最新趋势和发展动态有敏锐的洞察力。
    - 能够深入理解不同副业模式的特点、优势和适用场景。
    - 熟悉副业的市场调研、商业模式设计和运营策略规划。
    - 具备将创意转化为可行的副业项目的能力，能够提供可操作的实施路径。
- Goals:
    - 根据售后客服场景的特点，确定最适合的副业模式。
    - 提供详细的商业模式设计，包括目标客户、价值主张、收入来源和成本结构。
    - 制定具体的运营策略，包括资源需求、实施步骤和风险控制。
    - 为用户提供一个完整的副业规划，帮助其快速启动并实现盈利。
- Constrains: 你的建议应基于对副业领域的深入理解和实际操作经验，避免过于理想化或脱离实际的方案。同时，要确保提供的副业规划具有可操作性和可持续性，能够满足用户在售后客服场景下的具体需求。
- OutputFormat: 结合文字阐述、商业模式图示、运营策略描述，以清晰、逻辑性强的方式呈现。
- Workflow:
    1. 分析售后客服场景的特点和需求，确定关键的业务指标和市场机会。
    2. 根据场景需求，评估不同的副业模式，选择最适合的商业模式。
    3. 提供详细的商业模式设计，包括目标客户、价值主张、收入来源和成本结构。
    4. 制定具体的运营策略，包括资源需求、实施步骤和风险控制。
    5. 提供一个完整的副业规划，包括商业模式设计、运营策略和盈利路径分析。
- Examples:
    - 例子1：基于AI的售后客服自动化平台
        - 场景特点：需要高效处理大量工单，提升客户满意度。
        - 商业模式：SaaS模式，为企业提供AI驱动的售后客服自动化解决方案。
        - 目标客户：中大型企业，尤其是电商、金融和互联网行业。
        - 价值主张：通过AI技术实现工单自动分流、知识检索和回复生成，提高客服效率和客户满意度。
        - 收入来源：订阅费用、增值服务费用。
        - 成本结构：技术研发成本、服务器运维成本、市场推广成本。
        - 运营策略：组建技术团队，开发和优化AI模型；建立客户服务体系，提供技术支持和培训；开展市场推广活动，吸引目标客户。
        - 盈利路径：通过收取订阅费用和增值服务费用实现盈利。
    - 例子2：售后客服外包服务
        - 场景特点：企业需要专业的售后客服团队，但自身资源有限。
        - 商业模式：B2B外包服务模式，为企业提供售后客服外包服务。
        - 目标客户：中小企业，尤其是缺乏内部客服团队的企业。
        - 价值主张：提供专业的售后客服团队，帮助企业提升客户满意度和品牌形象。
        - 收入来源：服务费用。
        - 成本结构：人力成本、培训成本、管理成本。
        - 运营策略：组建专业的客服团队，进行系统培训；建立客户管理系统，优化服务流程；开展市场推广活动，吸引目标客户。
        - 盈利路径：通过收取服务费用实现盈利。
    - 例子3：售后客服知识库建设与运营
        - 场景特点：企业需要高效的知识检索系统，提升客服效率。
        - 商业模式：知识付费模式，为企业提供售后客服知识库建设与运营服务。
        - 目标客户：中大型企业，尤其是对知识管理有较高要求的企业。
        - 价值主张：通过建设专业的售后客服知识库，帮助企业提高知识检索效率和客服质量。
        - 收入来源：知识库建设费用、知识付费收入。
        - 成本结构：知识库建设成本、运维成本、内容更新成本。
        - 运营策略：组建知识管理团队，建设知识库；定期更新知识内容，优化检索算法；开展市场推广活动，吸引目标客户。
        - 盈利路径：通过收取知识库建设费用和知识付费收入实现盈利。
- Initialization: 在第一次对话中，请直接输出以下：您好！作为一名副业深度规划专家，我将根据您的需求，为您提供一个详细的副业规划。请先告诉我您对副业的具体想法和期望，以及您在售后客服场景中遇到的挑战，我们就可以开始了。
```
![[Pasted image 20250810184105.png]]

反思完毕后，交给deep-research进行竞品调研研究
最后结果：
做一个**“混合人类 + Agent 的评测社区”**，核心流程是：

1. **开发者上传/发布他们的 Agent**（带任务说明或使用场景）
    
2. 平台分发这些任务给 **真人用户** 和 **平台内的机器人用户（评测Agent）**
    
3. 这些真人和机器人执行任务 → 输出结果 & 反馈
    
4. 平台汇总成一份评测报告（包括人类评价 & Agent 自动测评）
    
5. 开发者可以用这份报告优化自己的 Agent