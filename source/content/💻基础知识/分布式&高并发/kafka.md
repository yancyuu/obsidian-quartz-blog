

## Kafka中发送消息之前做了什么

在Apache Kafka中，生产者（Producer）负责将消息发送到指定的主题（Topic）中。发送消息之前，生产者一般会执行以下几个步骤：

1. **初始化连接**：生产者首先需要与Kafka集群建立连接。这通常涉及到查找Kafka代理（Broker）地址和端口等配置信息。
2. **序列化**：生产者需要将要发送的消息（通常是对象或其他数据结构）序列化为字节数组，以便网络传输和Kafka存储。
3. **分区指定（可选）**：生产者可以明确指定消息应该发送到哪个分区。如果没有明确指定，则一般会根据某种算法（例如轮询、哈希等）自动选择一个分区。
4. **添加时间戳和其他元数据（可选）**：一些高级用例可能需要在消息中添加时间戳或其他元数据。
5. **压缩（可选）**：为了减少网络传输和存储的开销，生产者可以选择压缩消息。
6. **批处理（可选）**：为了提高效率，生产者通常会将多个消息组成一个批次（batch）进行发送。
7. **确认机制设置**：生产者可以设置不同级别的确认机制（acknowledgments），以确保消息是否成功写入Kafka。
8. **发送**：最后，生产者会将消息（或消息批次）发送到Kafka代理。如果设置了确认机制，它会等待代理的确认响应。
9. **错误处理**：如果在发送过程中出现错误（例如网络问题、代理崩溃等），生产者需要根据设置的重试策略进行相应的处理。
10. **关闭连接（可选）**：发送完成后，生产者可以选择关闭与Kafka集群的连接，尤其是在不再需要发送消息时。

## Kafka中发送消息之后了什么

**1. 生产者（Producer）到代理（Broker）**

- **序列化**: 生产者通常将消息序列化成字节数组。
- **分区选择**: 生产者确定该消息应发送到哪个主题（Topic）和分区（Partition）。
- **网络传输**: 生产者通过网络将消息发送到分区所在的Kafka代理（Broker）。

**2. 代理（Broker）内部处理**

- **接收和存储**: 代理接收来自生产者的消息，并将其追加到分区的日志（Log）文件中。
- **偏移量（Offset）**: 每条消息在分区内都有一个唯一的偏移量，用于在该分区内唯一地标识这条消息。
- **副本同步**: 如果分区有副本（Replica），消息会被复制到这些副本中。

**3. 消费者（Consumer）和其他下游系统**

- **拉取**: 消费者周期性地从代理拉取新的消息。
- **反序列化**: 消费者将接收到的字节数组反序列化成原始消息格式。
- **消息处理**: 消费者或下游系统对消息进行处理。

**4. 其他注意事项**

- **日志保留**: 代理会根据配置保留消息一段时间，之后可能会删除旧消息以释放存储空间。
    - **确认机制**: Kafka有多种消息确认机制，包括"acks"设置，以确保消息的可靠传输。

这个流程涉及多个环节和组件，而且可以根据配置和使用场景有所不同。然而，这些基本步骤通常都会存在。希望这能帮助您理解Kafka中消息发送后的一系列操作。

## 系统架构

[](https://wdoc-76491.picgzc.qpic.cn/MTY4ODg1MDUyMzIwODc3MQ_797993_whwK_lSG9309BUTd_1644924440?w=1558&h=738)

[](https://wdoc-76491.picgzc.qpic.cn/MTY4ODg1MDUyMzIwODc3MQ_746997_lAtHAcLpzu7eU26G_1644924440?w=1702&h=982)

同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中 leader 副本负责处理读写请求，follower 副本只负责与 leader 副本的消息同步。副本处于不同的 broker 中，当 leader 副本出现故障时，从 follower 副本中重新选举新的 leader 副本对外提供服务。Kafka 通过多副本机制实现了故障的自动转移，当 Kafka 集群中某个 broker 失效时仍然能保证服务可用。

[](https://wdoc-76491.picgzc.qpic.cn/MTY4ODg1MDUyMzIwODc3MQ_630413_Y-agT7ObineEe9zh_1644924440?w=1304&h=742)

## Kafka的生产者为什么要分区

### **1.提供负载均衡的能力**

### **2.实现系统的高伸缩性**（方便扩容）

分区是实现负载均衡以及高吞吐量的关键，需要合理分区才能避免数据倾斜

Kafka生产者的分区策略是决定生产者将消息发送到哪个分区的算法。Kafka提供默认的分区策略，同时它也支持自定义分区策略。常见的分区策略如下：

**轮询策略：**也称 Round-robin 策略，即顺序分配

**随机策略：**随意地将消息放置到任意一个分区上

**自定义key策略**：Kafka 允许为每条消息定义消息键（ Key），一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面。

leader副本和follwer副本

只有 Leader 才能对外提供读写服务，响应 Clients 端的请求。

Follower采用拉(PULL)的方式，被动地同步去Leader同步数据，

在 Leader所在的 Broker 宕机后，随时准备应聘 Leader 。

AR=ISR+OSR

分区中的所有副本统称为AR（Assigned Replicas）。

所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。

与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas）

简述 Follower 副本消息同步的完整流程

1.Follower 发送 FETCH 请求给 Leader

2.Leader 读日志文件中的消息数据，再更新它内存中的 Follower 副本的 **LEO （日志末端偏移量）**，更新为 FETCH 请求中的 fetchOffset 值。

3.Follower 接收到 FETCH 响应之后，把消息写入到底层日志，接着更新 LEO 和 HW 值。

Leader 和 Follower 的 HW 值更新时机是不同的，Follower 的 HW(消费者只能看见[Log Start Offset , HW) 之间的数据) 更新永远落后于 Leader 的HW。这种时间上的错配是造成各种不一致的原因。

[](https://wdoc-76491.picgzc.qpic.cn/MTY4ODg1MDUyMzIwODc3MQ_407721_fNBWgHyZSkyEctAF_1644924440?w=600&h=316)

### **为什么follower不提供对外读/为什么kafka不支持读写分离？**

1.自2.4+开始，Follower 能有限度地提供读服务。

2.主要原因是leader和follower的消息序列可能不一致（比如程序 Bug、网络问题等导致的）。（之前确保一致性的主要手段是高水位机制， 但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了 Leader Epoch机制。）

什么是消费者组？

多个消费者组成的一个group，组内所有消费者订阅同一个或多个topic来消费，每个分区只能有一个消费者消费。理想情况下，消费者实例的数量应该等Group订阅主题的分区总数。一个分区只能属于一个消费者线程。

### zookeeper的作用？

zookeeper是分布式协调服务，很多中间件底层都用到了它。对于kafka而言，主要有存放集群元数据（topic跟分区所有数据都存放zk）、成员管理（Broker 节点的注册、注销以及属性变更）、leader选举等作用。后面高版本的数据已不存放到zk，也不依赖zk做选举了。

为什么kafka采用pull的方式消费？

push：broker记录消费者的消费状态。broker在将消息推送到消费者后，标记这条消息为已消费，这种方式可能丢消息。比如，broker把消息发送出去后，当消费进程挂掉或者由于网络原因没有收到这条消息时，就有可能造成消息丢失。

pull：消费者控制偏移量，想处理多久的数据，处理多少数据，完全由消费者决定，好处是消费者可以根据自己的消费能力决定一次拉取多少数据处理，并且可以处理已消费过的数据。

kafka怎么做到不丢消息：消息交付可靠性保障

所谓的消息交付可靠性保障，是指 Kafka 对 Producer 和 Consumer 要处理的消息提供什么样的承诺。常见的承诺有以下三种：

**1.最多一次（at most once）：**消息可能会丢失，但绝不会被重复发送。

**2.至少一次（at least once）：**消息不会丢失，但有可能被重复发送。

**3.精确一次（exactly once）：**消息不会丢失，也不会被重复发送。

at most once：投递失败生产者不会重试

at least once：投递失败生产者会重试

**exactly once：通过幂等性和事务实现：**

**幂等producer（0.11+版本）：**enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。Kafka为了实现幂等性，它在底层设计架构中引入了ProducerID和SequenceNumber。在每个新的Producer初始化时，会被分配一个唯一的ProducerID，用来标识本次会话。 SequenceNumber：对于每个ProducerID，Producer发送数据的每个Topic和Partition都对应一个从0开始单调递增的SequenceNumber值。broker在内存维护(pid,seq)映射，收到消息后检查seq。producer在收到明确的的消息丢失ack，或者超时后未收到ack，要进行重试。

**事务producer：**能够保证将消息原子性地写入到多个分区中（这批消息要么全部写入成功，要么全部失败）

为什么kafka快？

**生产者角度:**

[页缓存] kafka往磁盘写数据时，会先写到页缓存里（也叫os cache），接下来由操作系统自己决定什么时候把os cache里的数据真的刷入磁盘文件中【跟es写入原理一样】

[磁盘顺序写] 仅将数据追加到文件的末尾

**消费者角度：**

[零拷贝技术]

如果不做优化，kafka从磁盘读数据发送给消费者，先要从os cache里拷贝数据到应用进程缓存，再从应用程序进程的缓存里拷贝数据到操作系统层面的Socket缓存里，最后从Socket缓存里提取数据后发送到网卡，最后发送出去给下游消费。需要经历两次拷贝，中间还要经历好几次上下文切换，非常消耗性能。

kafka在读数据时，直接将os cache数据发送到网卡，然后传输给消费者。socket缓存仅拷贝描述符过去，不拷贝数据

重平衡触发的条件和规避措施？

Rebalance 的触发条件有 3 个。

**1.消费组数发生变更**

**2.topic数发生变更**

**3.topic的分区数发生变更**

Rebalance 实在是太慢了，我们尽量避免一些非必要的Rebalance：

1.未能及时发送心跳，导致 Consumer 被“踢出”Group 而引发的

2.是Consumer 消费时间过长导致的，max.poll.interval.ms 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。

Kafka设计了一套消费者组状态机（State Machine），帮助协调者完成整个重平衡流程。

Java Consumer 为什么采用单线程来获取消息?

其实Java Consumer 是双线程的设计。一个线程是用户主线程，负责获取消息；另一个线程是心跳线程，监听消费者是否存活。

单线程轮询方式容易实现异步非阻塞，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。另外一个可能的好处是，可以简化代码的开发。多线程交互的代码是非常容易出错的。